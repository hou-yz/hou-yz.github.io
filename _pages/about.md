---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About
======
Yunzhong Hou (侯云钟) is a research fellow at the Australian National University, collaborating closely with [Prof. Tom Gedeon](https://staffportal.curtin.edu.au/staff/profile/view/tom-gedeon-5e48a1fd/#top) and [Prof. Liang Zheng](http://zheng-lab.cecs.anu.edu.au/). He completed his PhD at the same university in 2023, under the esteemed guidance of [Prof. Liang Zheng](http://zheng-lab.cecs.anu.edu.au/), [Prof. Stephen Gould](http://users.cecs.anu.edu.au/~sgould/), and [Prof. Hongdong Li](http://users.cecs.anu.edu.au/~hongdong/). Yunzhong's academic journey began at Tsinghua University, where he earned a bachelor's degree in electronic engineering in 2018.

Specializing in computer vision and deep learning, his current research interest lies in AI-based drone videography, camera control and optimizations for embodied agents, and multi-view detection and tracking. Yunzhong is actively involved in the academic community, contributing as a conference reviewer for prominent conferences such as CVPR, ECCV, ICCV, NeurIPS, ACM MM, and IJCAI. He also serves as a journal reviewer for respected publications like TPAMI, TIP, TMM, and TCSVT, and an area chair for ICASSP and ACM MM.


For more details, please find his CV [here](https://1drv.ms/b/s!AtzsQybTubHfhI8szRMzVSKg6dYy-Q?e=sFSths).

News
======

- *2023.12* **Our grant proposal _"Privacy-Percerving Perception for Robotics"_ is awarded by the [HMI seed grant](https://services.anu.edu.au/research-support/funding-opportunities/computing-for-social-good-seed-grants-2023) for 25,000 AUD! Big thank you to [Dylan](https://sites.google.com/view/djcampbell), [Rahul](https://rahulsho.me/), and [Mike](https://michaelrandallbarnes.com/about)!**

- *2023.12* **Check out our latest research on camera layout optimization _"Optimizing Camera Configurations for Multi-View Pedestrian Detection"_. [arxiv](https://arxiv.org/abs/2312.02144)**

- *2023.11* Our paper _"View-Coherent Correlation Consistency for Semi-Supervised Semantic Segmentation"_ is accepted by *Pattern recognition*. [paper](https://www.sciencedirect.com/science/article/pii/S0031320323007860).
- 
- *2023.06*   I was named outstanding reviewer for CVPR 2023!

- *2023.04*   Joined as a research fellow at ANU, working with [Prof. Tom Gedeon](https://staffportal.curtin.edu.au/staff/profile/view/tom-gedeon-5e48a1fd/#top) and [Dr. Liang Zheng](http://zheng-lab.cecs.anu.edu.au/). Excited!

- *2023.03*   Check out our latest research _"Learning to Select Camera Views: Efficient Multiview Understanding at Few Glances"_ on arXiv. [paper](https://arxiv.org/abs/2303.06145), [code](https://github.com/hou-yz/MVSelect)

- *2022.07-2022.10*   Internship at Amazon Web Services as a research scientist on vision-language tasks. Hello Bay Area!

- *2021.12*   Our paper _"[Adaptive Affinity for Associations in Multi-Target Multi-Camera Tracking](/publication/2022-tip-mtmc)"_ is accepted by *IEEE TIP*. [paper](https://ieeexplore.ieee.org/iel7/83/4358840/09646485.pdf), [code](https://github.com/hou-yz/DeepCC-local)

- *2021.07* Our paper _"[Ranking Models in Unlabeled New Environments](/publication/2021-iccv2021-ranking)"_ is accepted by *ICCV 2021*. [paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Sun_Ranking_Models_in_Unlabeled_New_Environments_ICCV_2021_paper.pdf), [code](https://github.com/sxzrt/Proxy-Set)

- *2021.07* Our paper _"[Multiview Detection with Shadow Transformer (and View-Coherent Data Augmentation)](/publication/2021-acmmm2021-mvdetr)"_ is accepted by *ACM MM 2021*. [paper](https://arxiv.org/abs/2108.05888), [code](https://github.com/hou-yz/MVDeTr)

- *2021.03* Our paper _"[Visualizing Adapted Knowledge in Domain Transfer](/publication/2020-cvpr2021-sfit)"_ is accepted by *CVPR 2021*.
[paper](https://arxiv.org/abs/2104.10602), [code](https://github.com/hou-yz/DA_visualization), [知乎-UDA可视化](https://zhuanlan.zhihu.com/p/369252839), [知乎-无需风格图像的风格迁移](https://zhuanlan.zhihu.com/p/371101640).


<!-- <img align="right" width="40" height="40" src="images/eccv-2020.png"> -->

- *2020.07* Our paper _"[Multiview Detection with Feature Perspective Transformation](/publication/2020-eccv2020-mvdet)"_ is accepted by *ECCV 2020*. 
[paper](https://arxiv.org/abs/2007.07247), [code](https://github.com/hou-yz/MVDet), [知乎](https://zhuanlan.zhihu.com/p/196771711), [MultiviewX dataset download](https://1drv.ms/u/s!AtzsQybTubHfgP9BJt2g7R_Ku4X3Pg?e=GFGeVn).


<!-- <img align="right" width="120" height="60" src="images/CVPR_Logo_Horz2_web.jpg"> -->

- *2020.03* Our paper _"[Learning to Structure an Image with Few Colors](/publication/2019-cvpr2020-colorcnn)"_ is accepted by *CVPR 2020*. 
[paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Hou_Learning_to_Structure_an_Image_With_Few_Colors_CVPR_2020_paper.pdf), [code](https://github.com/hou-yz/color_distillation), [知乎](https://zhuanlan.zhihu.com/p/148160812).


<!-- <img align="right" width="120" height="120" src="images/TLML_intro_narrow.png"> -->

- *2019.11* A new paper "[Locality aware appearance metric for multi-target multi-camera tracking](/publication/2019-arxiv-mtmc-metric)" is released on *arXiv*. 
[paper](https://arxiv.org/abs/1911.12037.pdf), [code](https://github.com/hou-yz/DeepCC-local), [知乎](https://zhuanlan.zhihu.com/p/96999382).


<!-- <img align="right" width="120" height="60" src="images/CVPR_Logo_Horz2_web.jpg">

- Two papers are submitted to CVPR 2020. -->

<!-- <img align="right" width="120" height="120" src="images/tracking_workshop.png"> -->

- *2019.06* Won 5th place out of 22 participants in multi-target multi-camera tracking in *CVPR 2019 AI-City Challenge*. [paper](http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Hou_A_Locality_Aware_City-Scale_Multi-Camera_Vehicle_Tracking_System_CVPRW_2019_paper.pdf), [code](https://github.com/hou-yz/DeepCC-local).

<!-- <img align="right" width="120" height="120" src="images/reid_workshop.png"> -->

- *2019.06* Won 3rd place out of 84 participants in vehicle re-identification in *CVPR 2019 AI-City Challenge*. [paper](http://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Lv_Vehicle_Re-Identification_with_Location_and_Time_Stamps_CVPRW_2019_paper.pdf), [code](https://github.com/hou-yz/open-reid-tracking).

<!-- <img align="right" width="120" height="120" src="images/2-step_pruning.png"> -->

- *2019.03* Our paper "[Improving Device-Edge Cooperative Inference of Deep Learning via 2-Step Pruning](/publication/2018-infocom2019workshop-pruning)" is accepted by *Infocom workshop on IECOO 2019*. [paper](https://arxiv.org/abs/1903.03472.pdf), [code](https://github.com/hou-yz/pytorch-pruning-2step).



Contact
------
Please contact me via [e-mail](mailto:yunzhong.hou@anu.edu.au).
